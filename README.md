# Deep_Learning_fourth_assignment

This repository is referred at the fourth assignment about Deep Learning course. Here is possible to see 2 exercise about the practice part. Also there is the file "Deep Learning Fourth assignment.pdf" that is the documentation requested.

This assignment has been completed by the Group 27 [Valentini Michel, Elma Nevala, Dovile Umbrasaite].


1. Take the model for the FashionMNIST or MNIST data set. Take 2 different examples
from two different classes. Use at least three local explanation methods and explain
reasons they are mapped to the true, the most likely, second most likely, and lest likely
class. Interpret the results. Are the explanations meaningful? Do they differ for diffe-
rent target outputs? What happens if the examples are adversarially attacked (with
a local change of only small parts of the image)? Also try this out experimentally.


2. Use a model which is trained together with a backdoor. Use two different global
explanation methods. Are these capable of detecting/explaining the existence of a
backdoor?



