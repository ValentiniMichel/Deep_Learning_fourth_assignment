{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import fashion_mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "import tensorflow as tf\n",
    "from skimage.color import gray2rgb\n",
    "import shap\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the FashionMNIST dataset\n",
    "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "# Preprocess the data\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0\n",
    "X_train = X_train.reshape(-1, 28, 28, 1)\n",
    "X_test = X_test.reshape(-1, 28, 28, 1)\n",
    "\n",
    "# Define the model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=5, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code starts by importing the necessary libraries and modules for building and training the model, loading the dataset, and performing the adversarial attack.\n",
    "\n",
    "The FashionMNIST dataset is loaded and preprocessed. The pixel values of the images are scaled to the range [0, 1] by dividing them by 255.0. The data is reshaped to have a shape of (-1, 28, 28, 1) to fit the input shape of the convolutional neural network.\n",
    "\n",
    "A Sequential model is defined, consisting of convolutional and pooling layers, followed by flattening and dense layers. The model is compiled with the Adam optimizer and sparse categorical cross-entropy loss function.\n",
    "\n",
    "The model is trained using the training data for 5 epochs with a batch size of 32. The validation data is used to evaluate the model's performance during training.\n",
    "\n",
    "The class names for the FashionMNIST dataset are defined for later use in displaying the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Select two examples\n",
    "example1_idx = np.argmax(y_test == 0)\n",
    "example2_idx = np.argmax(y_test == 1)\n",
    "\n",
    "example1 = X_test[example1_idx]\n",
    "example2 = X_test[example2_idx]\n",
    "\n",
    "# Convert grayscale image to RGB\n",
    "example2_rgb = gray2rgb(example2.reshape(28, 28))\n",
    "\n",
    "# Make predictions for the examples\n",
    "example1_pred = model.predict(example1.reshape(1, 28, 28, 1))\n",
    "example2_pred = model.predict(example2.reshape(1, 28, 28, 1))\n",
    "\n",
    "# Get the predicted classes and probabilities\n",
    "example1_class = np.argmax(example1_pred)\n",
    "example1_prob = example1_pred[0, example1_class]\n",
    "example1_second_prob = np.sort(example1_pred)[0, -2]\n",
    "example1_least_prob = np.sort(example1_pred)[0, -1]\n",
    "\n",
    "example2_class = np.argmax(example2_pred)\n",
    "example2_prob = example2_pred[0, example2_class]\n",
    "example2_second_prob = np.sort(example2_pred)[0, -2]\n",
    "example2_least_prob = np.sort(example2_pred)[0, -1]\n",
    "\n",
    "print(f\"Example 1: True Class - {class_names[0]}\")\n",
    "print(f\"           Predicted Class - {class_names[example1_class]}\")\n",
    "print(f\"           Probability - {example1_prob:.4f}\")\n",
    "print(f\"           Second Most Likely Probability - {example1_second_prob:.4f}\")\n",
    "print(f\"           Least Likely Probability - {example1_least_prob:.4f}\")\n",
    "print()\n",
    "print(f\"Example 2: True Class - {class_names[1]}\")\n",
    "print(f\"           Predicted Class - {class_names[example2_class]}\")\n",
    "print(f\"           Probability - {example2_prob:.4f}\")\n",
    "print(f\"           Second Most Likely Probability - {example2_second_prob:.4f}\")\n",
    "print(f\"           Least Likely Probability - {example2_least_prob:.4f}\")\n",
    "print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two examples (one with the true class of T-shirt/top and the other with the true class of Trouser) are selected from the test data.\n",
    "\n",
    "The grayscale image of the second example is converted to RGB format using the gray2rgb function from the skimage library.\n",
    "\n",
    "The model predicts the classes and probabilities for the two examples.\n",
    "\n",
    "The predicted classes, probabilities, and other information for the two examples are printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adversarial attack using FGSM\n",
    "\n",
    "# Set the epsilon value for FGSM\n",
    "epsilon = 0.1\n",
    "\n",
    "# Convert the examples to tensors\n",
    "example1_tensor = tf.convert_to_tensor(example1.reshape(1, 28, 28, 1), dtype=tf.float32)\n",
    "example2_tensor = tf.convert_to_tensor(example2.reshape(1, 28, 28, 1), dtype=tf.float32)\n",
    "\n",
    "# Use persistent gradient tape to compute gradients\n",
    "with tf.GradientTape(persistent=True) as tape:\n",
    "    tape.watch(example1_tensor)\n",
    "    tape.watch(example2_tensor)\n",
    "\n",
    "    # Compute the loss for the original examples\n",
    "    original_loss1 = tf.keras.losses.sparse_categorical_crossentropy(y_test[example1_idx], model(example1_tensor))\n",
    "    original_loss2 = tf.keras.losses.sparse_categorical_crossentropy(y_test[example2_idx], model(example2_tensor))\n",
    "\n",
    "# Compute the gradients of the loss with respect to the input examples\n",
    "gradient1 = tape.gradient(original_loss1, example1_tensor)\n",
    "gradient2 = tape.gradient(original_loss2, example2_tensor)\n",
    "\n",
    "# Generate the adversarial examples\n",
    "perturbed_example1 = example1_tensor + epsilon * tf.sign(gradient1)\n",
    "perturbed_example2 = example2_tensor + epsilon * tf.sign(gradient2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The adversarial attack in this code is implemented using the Fast Gradient Sign Method (FGSM), which is a simple yet effective technique for generating adversarial examples. Adversarial examples are input samples that are intentionally crafted to cause misclassification or unexpected behavior in machine learning models.\n",
    "\n",
    "Here's a breakdown of the adversarial attack part of the code:\n",
    "\n",
    "The epsilon value is set to determine the magnitude of the perturbation. It controls the size of the change applied to the original examples. A smaller epsilon value corresponds to a smaller change, while a larger epsilon value allows for a larger change.\n",
    "\n",
    "The original examples, example1 and example2, are converted to tensors (example1_tensor and example2_tensor) of data type tf.float32 to work with TensorFlow operations.\n",
    "\n",
    "A persistent gradient tape is created using tf.GradientTape(persistent=True). The persistent=True argument allows multiple gradient computations to be performed within the same tape context.\n",
    "\n",
    "The example1_tensor and example2_tensor are watched by the gradient tape using tape.watch() to ensure that the gradients with respect to these tensors are computed.\n",
    "\n",
    "The original loss for example1 and example2 is computed using the sparse_categorical_crossentropy loss function and the model's predictions for the respective examples.\n",
    "\n",
    "The gradients of the original loss with respect to example1_tensor and example2_tensor are computed using tape.gradient(original_loss1, example1_tensor) and tape.gradient(original_loss2, example2_tensor).\n",
    "\n",
    "The sign of the gradients is taken using tf.sign() to obtain the direction of change that maximizes the loss. This step determines the direction in which to perturb the examples.\n",
    "\n",
    "The perturbed examples, perturbed_example1 and perturbed_example2, are generated by adding the perturbation to the original examples. The perturbation is obtained by multiplying the sign of the gradients with the epsilon value and adding it to the original examples.\n",
    "\n",
    "The perturbed examples are then used to make predictions (perturbed_example1_pred and perturbed_example2_pred) using the trained model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the predicted classes and probabilities for the adversarial examples\n",
    "perturbed_example1_pred = model.predict(perturbed_example1)\n",
    "perturbed_example2_pred = model.predict(perturbed_example2)\n",
    "\n",
    "perturbed_example1_class = np.argmax(perturbed_example1_pred)\n",
    "perturbed_example1_prob = perturbed_example1_pred[0, perturbed_example1_class]\n",
    "\n",
    "perturbed_example2_class = np.argmax(perturbed_example2_pred)\n",
    "perturbed_example2_prob = perturbed_example2_pred[0, perturbed_example2_class]\n",
    "\n",
    "print(\"Adversarial Examples (FGSM):\")\n",
    "print(f\"Example 1: Predicted Class - {class_names[perturbed_example1_class]}\")\n",
    "print(f\"           Probability - {perturbed_example1_prob:.4f}\")\n",
    "print()\n",
    "print(f\"Example 2: Predicted Class - {class_names[perturbed_example2_class]}\")\n",
    "print(f\"           Probability - {perturbed_example2_prob:.4f}\")\n",
    "print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predicted classes and probabilities for the perturbed examples are obtained (perturbed_example1_class, perturbed_example1_prob, perturbed_example2_class, perturbed_example2_prob).\n",
    "\n",
    "Finally, the predicted classes and probabilities for the perturbed examples are printed, showing the effect of the adversarial attack on the model's predictions.\n",
    "\n",
    "The adversarial attack in this code modifies the original examples by introducing small changes based on the gradient information of the model. These changes are carefully crafted to deceive the model into making incorrect predictions. By controlling the epsilon value, you can adjust the level of perturbation and observe the impact on the model's behavior. Adversarial attacks like FGSM highlight the vulnerability of machine learning models and the need for robust defenses against such attacks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP Explanation\n",
    "background = X_train[np.random.choice(X_train.shape[0], 100, replace=False)]\n",
    "explainer = shap.GradientExplainer(model, background)\n",
    "shap_values = explainer.shap_values(example1.reshape(1, 28, 28, 1))\n",
    "shap.image_plot(shap_values, -example1.reshape(1, 28, 28, 1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SHAP (SHapley Additive exPlanations) explanation method is used to generate SHAP values for the first example. The background dataset is randomly sampled from the training data, and the GradientExplainer is created using the model and background data. SHAP values are computed for the example and plotted as an image using shap.image_plot.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DeepLIFT Explanation\n",
    "explainer = shap.DeepExplainer(model, background)\n",
    "deeplift_values = explainer.shap_values(example2.reshape(1, 28, 28, 1))\n",
    "shap.image_plot(deeplift_values, -example2.reshape(1, 28, 28, 1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The DeepLIFT explanation method is used to generate DeepLIFT values for the second example. The DeepExplainer is created using the model and background data. DeepLIFT values are computed for the example and plotted as an image using shap.image_plot.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Integrated Gradients Explanation\n",
    "baseline = np.zeros_like(example2).reshape(1, 28, 28, 1)\n",
    "explainer = shap.GradientExplainer(model, baseline)\n",
    "shap_values = explainer.shap_values(example2.reshape(1, 28, 28, 1))\n",
    "shap.image_plot(shap_values, -example2.reshape(1, 28, 28, 1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The Grad-CAM (Gradient-weighted Class Activation Mapping) explanation method is used to generate a heatmap for the second example. The RGB image is preprocessed by scaling its values and converting it to an array. A Grad-CAM model is created using the intermediate layer outputs and the model's final output. A gradient tape is used to compute the gradients of the predicted class's output with respect to the intermediate layer outputs. The gradients are multiplied with the intermediate layer outputs and averaged along the channel axis to obtain the heatmap. The heatmap is normalized and displayed using plt.imshow.\n",
    "\n",
    "The code ends here, and the results of the adversarial attack and explanations are displayed."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
